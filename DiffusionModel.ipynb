{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "_RfiQiBvplzI"
      },
      "outputs": [],
      "source": [
        "from torch.nn import Module,Sequential,Conv2d,GroupNorm,SiLU,Identity,Linear,LayerNorm,MultiheadAttention,ConvTranspose2d,ModuleList\n",
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def convBlock(in_dim,out_dim):\n",
        "  return Sequential(Conv2d(in_dim,out_dim,3,padding=1),GroupNorm(8,out_dim),SiLU())\n",
        "def timeEmeddingMLP(dim):\n",
        "  return Sequential(Linear(dim,dim*4),SiLU(),Linear(dim*4,dim))\n",
        "def FCN(dim):\n",
        "  return Sequential(Linear(dim,dim*4),SiLU(),Linear(dim*4,dim))\n",
        "\n",
        "\n",
        "\n",
        "class ResnetLayer(Module):\n",
        "  def __init__(self, in_dim, out_dim, time_dim=None):\n",
        "    super().__init__()\n",
        "\n",
        "    self.block1 = convBlock(in_dim, out_dim)\n",
        "    self.block2 = convBlock(out_dim, out_dim)\n",
        "\n",
        "    self.resBlock = convBlock(in_dim,out_dim)  if(in_dim!=out_dim) else Identity()\n",
        "    self.timeLinear = Sequential(SiLU(), Linear(time_dim, out_dim)) if time_dim else None\n",
        "\n",
        "  def forward(self,X,timeLatent=None):\n",
        "    y = self.block1(X)\n",
        "    if(self.timeLinear):\n",
        "      y = y + self.timeLinear(timeLatent).unsqueeze(-1).unsqueeze(-1)\n",
        "    y = self.block2(y)\n",
        "\n",
        "    y = y + self.resBlock(X)\n",
        "\n",
        "    return y\n",
        "\n",
        "class SinusoidalEmbeddings(Module):\n",
        "  def __init__(self, dim):\n",
        "\n",
        "    super().__init__()\n",
        "\n",
        "    self.dim = dim\n",
        "  def forward(self,timestep):\n",
        "\n",
        "    dim = self.dim//2\n",
        "    freqs = torch.pow(10000, -torch.arange(dim, dtype=torch.float32) / dim)\n",
        "    x = torch.tensor([timestep], dtype=torch.float32)\n",
        "    x = x[:, None] * freqs[None]\n",
        "    return torch.cat([torch.cos(x), torch.sin(x)], dim=-1)\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "gWnWMlZQtdNW"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class UnetAttention(Module):\n",
        "  def __init__(self, dim, heads):\n",
        "    super().__init__()\n",
        "\n",
        "    self.layerNorm1 = LayerNorm(dim)\n",
        "    self.layerNorm2 = LayerNorm(dim)\n",
        "\n",
        "    self.conv_in = Conv2d(dim, dim ,kernel_size=1, padding=0)\n",
        "    self.conv_out = Conv2d(dim, dim ,kernel_size=1, padding=0)\n",
        "\n",
        "    self.qkv_linear = Linear(dim,dim*3)\n",
        "    self.MHA = MultiheadAttention(dim , heads)\n",
        "    self.fcn = FCN(dim)\n",
        "\n",
        "  def attn(self,X):\n",
        "    q,k,v = self.qkv_linear(X).chunk(3,dim=-1)\n",
        "    return self.MHA(q,k,v)[0]\n",
        "  def forward(self,X):\n",
        "\n",
        "    y = self.conv_in(X)\n",
        "\n",
        "    # convert image format to sequence format\n",
        "\n",
        "    b,c,h,w = y.shape\n",
        "\n",
        "    y = y.view((b, c, h * w))\n",
        "    y_r = y.transpose(-1,-2)\n",
        "\n",
        "    y = self.layerNorm1(y_r)\n",
        "    y = self.attn(y)\n",
        "\n",
        "    y_r = y + y_r\n",
        "\n",
        "    y = self.layerNorm2(y_r)\n",
        "    y = self.fcn(y)\n",
        "\n",
        "    y = y + y_r\n",
        "\n",
        "    y  = y.transpose(-1,-2)\n",
        "    y = y.view((b, c, h , w))\n",
        "\n",
        "    y = self.conv_out(y)\n",
        "\n",
        "    # transformer under unet have property to add the input at end\n",
        "\n",
        "    return y + X\n",
        "class SamplingBlock(Module):\n",
        "  def __init__(self,indim, outdim, timedim, no_heads):\n",
        "    super().__init__()\n",
        "\n",
        "    self.res_block1 = ResnetLayer(indim, outdim, timedim)\n",
        "    self.res_block2 = ResnetLayer(outdim, outdim, timedim)\n",
        "    self.attn_block = UnetAttention(outdim,no_heads)\n",
        "  def forward(self, X, time):\n",
        "    y = self.res_block1(X,time)\n",
        "    y = self.res_block2(y,time)\n",
        "    y = self.attn_block(y)\n",
        "\n",
        "    return y"
      ],
      "metadata": {
        "id": "lW6r9WBaqA9l"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class downSamplingBlock(SamplingBlock):\n",
        "  def __init__(self,indim, outdim, timedim, no_heads, down_sample=False):\n",
        "    super().__init__(indim, outdim, timedim, no_heads)\n",
        "    self.down_sample =Conv2d(outdim, outdim, kernel_size=4, stride=2, padding=1) if down_sample else None\n",
        "\n",
        "\n",
        "  def forward(self,X,time):\n",
        "    y = super().forward(X,time)\n",
        "    if(self.down_sample):\n",
        "      y = self.down_sample(y)\n",
        "    return y\n",
        "\n",
        "class upSamplingBlock(SamplingBlock):\n",
        "  def __init__(self,indim, outdim, timedim, no_heads, up_sample=False):\n",
        "    super().__init__(indim, outdim, timedim, no_heads)\n",
        "    self.up_sample =ConvTranspose2d(outdim, outdim, kernel_size=4, stride=2, padding=1) if up_sample else None\n",
        "\n",
        "\n",
        "  def forward(self,X,time):\n",
        "    y = super().forward(X,time)\n",
        "    if(self.up_sample):\n",
        "      y = self.up_sample(y)\n",
        "    return y"
      ],
      "metadata": {
        "id": "Ua1k_mDe8lt2"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def bottleNeckBlock(dim, heads):\n",
        "  return Sequential(\n",
        "      ResnetLayer(dim, dim, None),\n",
        "      UnetAttention(dim,heads),\n",
        "      ResnetLayer(dim, dim, None),\n",
        "  )"
      ],
      "metadata": {
        "id": "jm5bEw6eVrZi"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class UNET(Module):\n",
        "  def __init__(self, config):\n",
        "\n",
        "    super().__init__()\n",
        "\n",
        "    self.timeEmbedding  = Sequential(SinusoidalEmbeddings(config.base_dim),timeEmeddingMLP(config.base_dim))\n",
        "\n",
        "    self.init_conv =Conv2d(config.channels, config.base_dim, 7, padding=3)\n",
        "\n",
        "    self.encoder = ModuleList([ downSamplingBlock(indim, outdim,config.base_dim, config.heads,index!=len(config.downsamplingDimensions)) for index,(indim, outdim) in enumerate(config.downsamplingDimensions,start=1) ])\n",
        "    self.bottleNeck = bottleNeckBlock(config.downsamplingDimensionsLast,config.heads)\n",
        "    self.decoder = ModuleList([ upSamplingBlock(indim, outdim,config.base_dim, config.heads,index!=1) for index,(indim, outdim) in enumerate(config.upsamplingDimensions,start=1) ])\n",
        "\n",
        "    outdim = config.upsamplingDimensionsLast\n",
        "    self.finalConv = Sequential(\n",
        "        convBlock(outdim, outdim),\n",
        "        Conv2d(outdim,config.channels,3,1)\n",
        "    )\n",
        "\n",
        "  def forward(self,X, time_step):\n",
        "\n",
        "    time_Embedding = self.timeEmbedding(time_step)\n",
        "    skip_connections = []\n",
        "\n",
        "    y = self.init_conv(X)\n",
        "    for layer in self.encoder:\n",
        "      y = layer(y,time_Embedding)\n",
        "      skip_connections.append(y)\n",
        "\n",
        "    y = self.bottleNeck(y)\n",
        "\n",
        "    for layer in self.decoder:\n",
        "      print(y.shape,skip_connections[-1].shape)\n",
        "      y = torch.cat([y, skip_connections.pop()],dim=1)\n",
        "      y = layer(y,time_Embedding)\n",
        "      print(y.shape)\n",
        "\n",
        "    y = self.finalConv(y)\n",
        "\n",
        "    return y\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "OLfeU4fkrvKo"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DiffusionModelConfig():\n",
        "  base_dim = 64\n",
        "\n",
        "  downsamplingDimensions = [(64,128),(128,256),(256,512),(512,1024)]\n",
        "  downsamplingDimensionsLast = 1024\n",
        "  upsamplingDimensions = [(2048,1024),(1536,512),(768,256),(384,128)]\n",
        "  upsamplingDimensionsLast = 128\n",
        "\n",
        "  channels = 3\n",
        "  heads = 4\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "To_njOaGi5yN"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = UNET(DiffusionModelConfig)\n",
        "X = torch.randn(1,3,256,256)"
      ],
      "metadata": {
        "id": "i-I736O80tTh"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MhRdV9p72rJT"
      },
      "execution_count": 9,
      "outputs": []
    }
  ]
}